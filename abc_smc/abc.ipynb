{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "92551b4b-9262-48d1-8559-b17c21d2c267",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'dask'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mstats\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m uniform, norm\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mdask\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdataframe\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mdd\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# SIR Models\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21msir_basic\u001b[39m(y, t, alpha, gamma, d, v):\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'dask'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.integrate import odeint\n",
    "from scipy.stats import uniform, norm\n",
    "import matplotlib.pyplot as plt\n",
    "import dask.dataframe as dd\n",
    "\n",
    "\n",
    "\n",
    "# SIR Models\n",
    "\n",
    "def sir_basic(y, t, alpha, gamma, d, v):\n",
    "    S, I, R = y\n",
    "    dSdt = alpha - gamma * S * I - d * S\n",
    "    dIdt = gamma * S * I - v * I - d * I\n",
    "    dRdt = v * I - d * R\n",
    "    return [dSdt, dIdt, dRdt]\n",
    "\n",
    "\n",
    "def sir_delayed(y, t, alpha, gamma, d, v, tau):\n",
    "    S, I, R = y\n",
    "    dSdt = alpha - gamma * S * I - d * S\n",
    "    dIdt = gamma * S * I - v * I - d * I\n",
    "    dRdt = v * I - d * R\n",
    "    return [dSdt, dIdt, dRdt]\n",
    "\n",
    "\n",
    "def sir_latent(y, t, alpha, gamma, d, v, delta):\n",
    "    S, L, I, R = y\n",
    "    dSdt = alpha - gamma * S * I - d * S\n",
    "    dLdt = gamma * S * I - delta * L - d * L\n",
    "    dIdt = delta * L - v * I - d * I\n",
    "    dRdt = v * I - d * R\n",
    "    return [dSdt, dLdt, dIdt, dRdt]\n",
    "\n",
    "\n",
    "def sir_reinfection(y, t, alpha, gamma, d, v, e):\n",
    "    S, I, R = y\n",
    "    dSdt = alpha - gamma * S * I - d * S + e * R\n",
    "    dIdt = gamma * S * I - v * I - d * I\n",
    "    dRdt = v * I - (d + e) * R\n",
    "    return [dSdt, dIdt, dRdt]\n",
    "\n",
    "# Simulation functions with noise\n",
    "def simulate_sir_basic(theta, t_obs, noise_std=0.5):\n",
    "    alpha, gamma, d, v = theta\n",
    "    y0 = [20, 10, 0]  # Initial conditions: S, I, R\n",
    "    sol = odeint(sir_basic, y0, t_obs, args=(alpha, gamma, d, v))\n",
    "    noisy_sol = sol + np.random.normal(0, noise_std, sol.shape)\n",
    "    return noisy_sol.flatten()\n",
    "\n",
    "\n",
    "def simulate_sir_delayed(theta, t_obs, noise_std=0.5):\n",
    "    alpha, gamma, d, v, tau = theta\n",
    "    y0 = [20, 10, 0]\n",
    "    sol = odeint(sir_delayed, y0, t_obs, args=(alpha, gamma, d, v, tau))\n",
    "    noisy_sol = sol + np.random.normal(0, noise_std, sol.shape)\n",
    "    return noisy_sol.flatten()\n",
    "\n",
    "def simulate_sir_latent(theta, t_obs, noise_std=0.5):\n",
    "    alpha, gamma, d, v, delta = theta\n",
    "    y0 = [20, 0, 10, 0]  # S, L, I, R\n",
    "    sol = odeint(sir_latent, y0, t_obs, args=(alpha, gamma, d, v, delta))\n",
    "    noisy_sol = sol + np.random.normal(0, noise_std, sol.shape)\n",
    "    return noisy_sol[:, [0,2,3]].flatten()  # Observe S, I, R\n",
    "\n",
    "def simulate_sir_reinfection(theta, t_obs, noise_std=0.5):\n",
    "    alpha, gamma, d, v, e = theta\n",
    "    y0 = [20, 10, 0]\n",
    "    sol = odeint(sir_reinfection, y0, t_obs, args=(alpha, gamma, d, v, e))\n",
    "    noisy_sol = sol + np.random.normal(0, noise_std, sol.shape)\n",
    "    return noisy_sol.flatten()\n",
    "\n",
    "\n",
    "\n",
    "# Distance function\n",
    "def distance(sim_data, observed_data):\n",
    "    return np.sum((sim_data - observed_data) ** 2)\n",
    "\n",
    "\n",
    "# Normalize weights\n",
    "def normalize_weights(weights):\n",
    "    total_weight = np.sum(weights)\n",
    "    return np.array(weights) / total_weight if total_weight > 0 else np.zeros_like(weights)\n",
    "\n",
    "\n",
    "# Sample initial particles\n",
    "def sample_initial_particles(N, models, model_prior, epsilons, observed_data, t_obs):\n",
    "    particles, weights = {m: [] for m in range(len(models))}, {m: [] for m in range(len(models))}\n",
    "    num_particles, attempt_count, max_attempts = 0, 0, N * 100000\n",
    "\n",
    "    while num_particles < N and attempt_count < max_attempts:\n",
    "        m = np.random.choice(len(models), p=model_prior)\n",
    "        params = [prior.rvs() for prior in models[m]['priors']]\n",
    "        sim_data = models[m]['simulate'](params, t_obs)\n",
    "        attempt_count += 1\n",
    "\n",
    "        if distance(sim_data, observed_data) <= epsilons[0]:\n",
    "            particles[m].append(params)\n",
    "            weights[m].append(1.0)\n",
    "            num_particles += 1\n",
    "            print(f\"Accepted {num_particles}/{N} particles (Model {m})\")\n",
    "\n",
    "    if num_particles < N:\n",
    "        raise RuntimeError(f\"Stopped after {attempt_count} attempts. Only {num_particles} particles accepted.\")\n",
    "\n",
    "    for m in particles:\n",
    "        weights[m] = normalize_weights(weights[m]) if particles[m] else []\n",
    "    return particles, weights\n",
    "\n",
    "\n",
    "# Perturb parameters\n",
    "def perturb_parameters(prev_params, model):\n",
    "    return [prev + sigma*np.random.uniform(-1, 1) for prev, sigma in zip(prev_params, model['kernel_sigma'])]\n",
    "\n",
    "\n",
    "# Check prior bounds\n",
    "def is_within_prior_bounds(params, priors):\n",
    "    return all(prior.ppf(0) <= param <= prior.ppf(1) for param, prior in zip(params, priors))\n",
    "\n",
    "\n",
    "# Compute weight\n",
    "def compute_weight(proposed_params, particles, weights, model):\n",
    "    prior_density = np.prod([prior.pdf(p) for prior, p in zip(model['priors'], proposed_params)])\n",
    "    denominator = sum(\n",
    "        w * np.prod([norm(p_old, sigma).pdf(p_new) for p_old, p_new, sigma in zip(p, proposed_params, model['kernel_sigma'])])\n",
    "        for p, w in zip(particles, weights)\n",
    "    )\n",
    "    return prior_density / (denominator + 1e-12)\n",
    "\n",
    "\n",
    "# Generate new population\n",
    "def generate_population(N, T, t, particles, weights, models, model_prior, epsilons, observed_data, t_obs):\n",
    "    new_particles, new_weights, num_accepted = {m: [] for m in range(len(models))}, {m: [] for m in\n",
    "                                                                                     range(len(models))}, 0\n",
    "    total_runs=0\n",
    "    while num_accepted < N:\n",
    "        total_runs+=1\n",
    "        m = np.random.choice(len(models), p=model_prior)\n",
    "        if not particles[t - 1][m]:\n",
    "            continue\n",
    "        idx = np.random.choice(len(particles[t - 1][m]), p=weights[t - 1][m])\n",
    "        prev_params = particles[t - 1][m][idx]\n",
    "        proposed_params = perturb_parameters(prev_params, models[m])\n",
    "\n",
    "        if not is_within_prior_bounds(proposed_params, models[m]['priors']):\n",
    "            continue\n",
    "\n",
    "        sim_data = models[m]['simulate'](proposed_params, t_obs)\n",
    "        if distance(sim_data, observed_data) <= epsilons[t]:\n",
    "            weight = compute_weight(proposed_params, particles[t - 1][m], weights[t - 1][m], models[m])\n",
    "            new_particles[m].append(proposed_params)\n",
    "            new_weights[m].append(weight)\n",
    "            num_accepted += 1\n",
    "            print(f\"Population {t}: Accepted {num_accepted}/{N} particles (Model {m})\")\n",
    "\n",
    "    acceptance_rate=num_accepted/total_runs\n",
    "    print(f\"Acceptance rate: {acceptance_rate:.2%} for \")\n",
    "\n",
    "\n",
    "    for m in new_particles:\n",
    "        new_weights[m] = normalize_weights(new_weights[m]) if new_particles[m] else []\n",
    "    return new_particles, new_weights\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Main ABC SMC function\n",
    "def abc_smc_model_selection(N, T, epsilons, models, model_prior, observed_data, t_obs):\n",
    "    particles, weights = sample_initial_particles(N, models, model_prior, epsilons, observed_data, t_obs)\n",
    "    all_particles, all_weights = [particles], [weights]\n",
    "\n",
    "    for t in range(1, T):\n",
    "        print(f\"Processing population {t}/{T - 1}\")\n",
    "        new_particles, new_weights = generate_population(N, T, t, all_particles, all_weights, models, model_prior,\n",
    "                                                         epsilons, observed_data, t_obs)\n",
    "        all_particles.append(new_particles)\n",
    "        all_weights.append(new_weights)\n",
    "\n",
    "\n",
    "    return all_particles, all_weights\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Define SIR models\n",
    "    models = [\n",
    "        {   # Model 0: Basic SIR (alpha, gamma, d, v,S0)\n",
    "            'simulate': simulate_sir_basic,\n",
    "            'priors': [uniform(0, 1), uniform(0, 0.1), uniform(0, 0.1), uniform(37, 100)],\n",
    "            'kernel_sigma': [0.05, 0.01, 0.01, 0.05]\n",
    "        },\n",
    "        {   # Model 1: Delayed SIR (placeholder)\n",
    "            'simulate': simulate_sir_delayed,\n",
    "            'priors': [uniform(0, 1), uniform(0, 0.1), uniform(0, 0.1), uniform(0, 0.5), uniform(37, 100)],\n",
    "            'kernel_sigma': [0.05, 0.01, 0.01, 0.05, 0.1]\n",
    "        },\n",
    "        {   # Model 2: Latent phase SIR\n",
    "            'simulate': simulate_sir_latent,\n",
    "            'priors': [uniform(0, 1), uniform(0, 0.1), uniform(0, 0.1), uniform(0, 0.5), uniform(37, 100)],\n",
    "            'kernel_sigma': [0.05, 0.01, 0.01, 0.05, 0.1]\n",
    "        },\n",
    "        {   # Model 3: Reinfection SIR\n",
    "            'simulate': simulate_sir_reinfection,\n",
    "            'priors': [uniform(0, 1), uniform(0, 0.1), uniform(0, 0.1), uniform(0, 0.5), uniform(37, 100)],\n",
    "            'kernel_sigma': [0.05, 0.01, 0.01, 0.05, 0.05]\n",
    "        }\n",
    "    ]\n",
    "    model_prior = [0.25, 0.25, 0.25, 0.25]  # Uniform prior\n",
    "\n",
    "    # Generate observed data from true model (Basic SIR)\n",
    "    t_obs = np.linspace(0, 11, 12)\n",
    "    true_params = [0.01, 0.005, 0.001, 0.1]  # alpha, gamma, d, v\n",
    "    observed_data = simulate_sir_basic(true_params, t_obs, noise_std=0.2)\n",
    "\n",
    "    # ABC SMC parameters\n",
    "    N = 1000  # Particles per population\n",
    "    T = 15   # Populations\n",
    "    epsilons = [ 100, 90, 80, 73, 70, 60, 50, 40, 30, 25, 20, 16, 15, 14, 13.8]  # Tolerance schedule\n",
    "    print(\"\\nbefore abc\")\n",
    "\n",
    "    # Run ABC SMC\n",
    "    particles, weights = abc_smc_model_selection(N, T, epsilons, models, model_prior, observed_data, t_obs)\n",
    "\n",
    "    # Analyze results\n",
    "    final_particles = particles[-1]\n",
    "    final_weights = weights[-1]\n",
    "    model_counts = {m: len(final_particles.get(m, [])) for m in range(len(models))}\n",
    "    total = sum(model_counts.values())\n",
    "    print(\"\\nModel posterior probabilities:\")\n",
    "    for m in range(len(models)):\n",
    "        print(f\"Model {m}: {model_counts[m]/total:.2%}\")\n",
    "\n",
    "    # Plot results\n",
    "    plt.figure()\n",
    "    for m in range(len(models)):\n",
    "        probs = [len(p.get(m, []))/N for p in particles]\n",
    "        plt.plot(probs, label=f'Model {m}')\n",
    "    plt.xlabel('Population')\n",
    "    plt.ylabel('Model Probability')\n",
    "    plt.title('SIR Model Selection Across Populations')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    population = final_particles\n",
    "    model_counts = {m: len(population[m]) for m in population}\n",
    "\n",
    "    models = list(model_counts.keys())  # Model indices\n",
    "    counts = list(model_counts.values())  # Particle counts\n",
    "\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    plt.bar(models, counts, tick_label=[f\"Model {m}\" for m in models], color='skyblue', edgecolor='black')\n",
    "    plt.xlabel(\"Model Index\")\n",
    "    plt.ylabel(\"Number of Particles\")\n",
    "    plt.title(f\"Particle Count per Model\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92451534-6d08-499e-81f7-afa47fa114ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04d9b7b6-5d8b-40c0-82c2-37b2480ab56c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
